{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama # will be used for prompting\n",
    "from langchain.vectorstores import Chroma # will be used for vectordb store\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema import Document # will be used to store text in vector store \n",
    "import os\n",
    "from kokoro import KPipeline\n",
    "import soundfile as sf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\")\n",
    "embedding = OllamaEmbeddings(model=\"llama3\")\n",
    "PERSIST_DIR = \"vectordb\"\n",
    "db = Chroma(persist_directory=PERSIST_DIR, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_unprocessed_idea(db):\n",
    "    results = db.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "    unprocessed = [\n",
    "        (meta[\"timestamp\"], Document(page_content=doc, metadata=meta))\n",
    "        for meta, doc in zip(results[\"metadatas\"], results[\"documents\"])\n",
    "        if not meta.get(\"processed\", False)\n",
    "    ]\n",
    "\n",
    "    if not unprocessed:\n",
    "        print(\"No unprocessed ideas found.\")\n",
    "        return None\n",
    "\n",
    "    unprocessed_sorted = sorted(unprocessed, key=lambda x: x[0], reverse=True)\n",
    "    _, document = unprocessed_sorted[0]\n",
    "\n",
    "    print(f\"Most recent unprocessed idea ID: {document.metadata.get('id')}\")\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent unprocessed idea ID: 1b6c1749-2bfe-4078-bd43-1a660dec2099\n",
      "\"Hey, have you ever struggled with building a mobile app that can handle real-time analytics and data visualizations? Yeah, I know what it's like - it's like trying to solve a puzzle blindfolded! But fear not, my friends, because Amazon QuickSight is here to save the day. It's a fast, easy-to-use business intelligence service that lets you create stunning dashboards and reports in minutes. So why would you use something like this? Well, imagine you're building an app for sports teams to track their performance metrics - QuickSight makes it easy to visualize complex data and spot trends.\n",
      "\n",
      "To set it up, you can just upload your data and let the algorithms do the heavy lifting. No coding required! And did you know that many companies are already using QuickSight to gain insights from their data? Yeah, it's that powerful. So if you're building something cool with data and want to unlock its secrets, give Amazon QuickSight a try. Let me know in the comments below - what's your favorite way to visualize data or create business intelligence reports?\"\n"
     ]
    }
   ],
   "source": [
    "most_recent_idea = get_most_recent_unprocessed_idea(db)\n",
    "if most_recent_idea:\n",
    "    print(most_recent_idea.page_content) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_text = most_recent_idea.page_content if most_recent_idea else \"Hello from Kokoro TTS!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ig-reel-env/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ig-reel-env/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "pipeline = KPipeline(lang_code='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate audio from the script\n",
    "generator = pipeline(script_text, voice='af_heart', speed=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all audio chunks and timing information\n",
    "audio_chunks = []\n",
    "subtitle_entries = []\n",
    "current_time = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: \"Hey, have you ever struggled with building a mobile app that can handle real-time analytics and data visualizations? Yeah, I know what it's like - it's like trying to solve a puzzle blindfolded! But fear not, my friends, because Amazon QuickSight is here to save the day. It's a fast, easy-to-use business intelligence service that lets you create stunning dashboards and reports in minutes. So why would you use something like this?\n",
      "Chunk 1: Well, imagine you're building an app for sports teams to track their performance metrics - QuickSight makes it easy to visualize complex data and spot trends.\n",
      "Chunk 2: To set it up, you can just upload your data and let the algorithms do the heavy lifting. No coding required! And did you know that many companies are already using QuickSight to gain insights from their data? Yeah, it's that powerful. So if you're building something cool with data and want to unlock its secrets, give Amazon QuickSight a try. Let me know in the comments below - what's your favorite way to visualize data or create business intelligence reports?\"\n"
     ]
    }
   ],
   "source": [
    "for i, (graphemes, phonemes, audio) in enumerate(generator):\n",
    "    audio_chunks.append(audio)\n",
    "    \n",
    "    # Calculate timing for subtitles (assuming 24000 sample rate)\n",
    "    chunk_duration = len(audio) / 24000  # duration in seconds\n",
    "    start_time = current_time\n",
    "    end_time = current_time + chunk_duration\n",
    "    \n",
    "    # Split long text into smaller subtitle chunks (max ~50 characters per line)\n",
    "    words = graphemes.split()\n",
    "    subtitle_lines = []\n",
    "    current_line = \"\"\n",
    "    \n",
    "    for word in words:\n",
    "        if len(current_line + \" \" + word) <= 50:\n",
    "            current_line += (\" \" + word) if current_line else word\n",
    "        else:\n",
    "            if current_line:\n",
    "                subtitle_lines.append(current_line)\n",
    "            current_line = word\n",
    "    \n",
    "    if current_line:\n",
    "        subtitle_lines.append(current_line)\n",
    "    \n",
    "    # If text is short enough, keep as single subtitle\n",
    "    if len(subtitle_lines) <= 2:\n",
    "        subtitle_lines = [graphemes]\n",
    "    \n",
    "    # Create subtitle entries for each line\n",
    "    line_duration = chunk_duration / len(subtitle_lines)\n",
    "    for j, line in enumerate(subtitle_lines):\n",
    "        line_start_time = start_time + (j * line_duration)\n",
    "        line_end_time = start_time + ((j + 1) * line_duration)\n",
    "        \n",
    "        # Format times for SRT (HH:MM:SS,mmm)\n",
    "        line_start_str = f\"{int(line_start_time//3600):02d}:{int((line_start_time%3600)//60):02d}:{int(line_start_time%60):02d},{int((line_start_time%1)*1000):03d}\"\n",
    "        line_end_str = f\"{int(line_end_time//3600):02d}:{int((line_end_time%3600)//60):02d}:{int(line_end_time%60):02d},{int((line_end_time%1)*1000):03d}\"\n",
    "        \n",
    "        subtitle_entries.append({\n",
    "            'index': len(subtitle_entries) + 1,\n",
    "            'start_time': line_start_str,\n",
    "            'end_time': line_end_str,\n",
    "            'text': line.strip()\n",
    "        })\n",
    "    \n",
    "    current_time = end_time\n",
    "    print(f\"Chunk {i}: {graphemes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output.wav with 3 chunks\n"
     ]
    }
   ],
   "source": [
    "# Combine all audio chunks into a single file\n",
    "if audio_chunks:\n",
    "    combined_audio = np.concatenate(audio_chunks)\n",
    "    sf.write(\"output.wav\", combined_audio, 24000)\n",
    "    print(f\"Generated output.wav with {len(audio_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output.srt with 23 subtitle entries\n"
     ]
    }
   ],
   "source": [
    "# Create SRT subtitle file\n",
    "with open(\"output.srt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in subtitle_entries:\n",
    "        f.write(f\"{entry['index']}\\n\")\n",
    "        f.write(f\"{entry['start_time']} --> {entry['end_time']}\\n\")\n",
    "        f.write(f\"{entry['text']}\\n\\n\")\n",
    "\n",
    "print(f\"Generated output.srt with {len(subtitle_entries)} subtitle entries\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ig-reel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
