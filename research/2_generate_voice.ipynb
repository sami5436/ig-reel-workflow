{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa05d037",
   "metadata": {},
   "source": [
    "This will be focused on generating the voice locally.\n",
    "- the script will be passed on (or queried in the vector db from the latest entry )\n",
    "- then call the TTS api to actually convert it into an mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f928d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "import soundfile as sf\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13edcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama # will be used for prompting\n",
    "from langchain.vectorstores import Chroma # will be used for vectordb store\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema import Document # will be used to store text in vector store \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51fdde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/p8kgtvm572d51cr90k19v_580000gn/T/ipykernel_22453/1332557208.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3\")\n",
      "/var/folders/90/p8kgtvm572d51cr90k19v_580000gn/T/ipykernel_22453/1332557208.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=PERSIST_DIR, embedding_function=embedding)\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3\")\n",
    "embedding = OllamaEmbeddings(model=\"llama3\")\n",
    "PERSIST_DIR = \"vectordb\"\n",
    "db = Chroma(persist_directory=PERSIST_DIR, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088fdbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document  # or adjust import to your LangChain version\n",
    "\n",
    "def get_most_recent_unprocessed_idea(db):\n",
    "    results = db.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "    unprocessed = [\n",
    "        (meta[\"timestamp\"], Document(page_content=doc, metadata=meta))\n",
    "        for meta, doc in zip(results[\"metadatas\"], results[\"documents\"])\n",
    "        if not meta.get(\"processed\", False)\n",
    "    ]\n",
    "\n",
    "    if not unprocessed:\n",
    "        print(\"No unprocessed ideas found.\")\n",
    "        return None\n",
    "\n",
    "    unprocessed_sorted = sorted(unprocessed, key=lambda x: x[0], reverse=True)\n",
    "    _, document = unprocessed_sorted[0]\n",
    "\n",
    "    print(f\"Most recent unprocessed idea ID: {document.metadata.get('id')}\")\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c7d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent unprocessed idea ID: 85c9b47a-0d2f-4f36-b3f9-8a22087c9489\n",
      "Hey everyone, have you ever wondered how some of your favorite e-commerce sites can handle millions of orders in a single day without breaking a sweat? Well, it's all thanks to Amazon Simple Queue Service, or SQS for short.\n",
      "\n",
      "So, what is SQS? Simply put, it's a messaging service that allows different parts of an application to communicate with each other without actually being connected. Think of it like a postal system - your app sends a message to the queue, and then another part of the app can pick it up whenever it's ready.\n",
      "\n",
      "You'd use SQS when you have multiple microservices or tasks that need to be processed in a specific order, but they don't necessarily need to talk to each other directly. For example, imagine you're building an online ordering system where orders are processed by different teams - customer support, fulfillment, and shipping. Each team needs to receive the order at a different time, and SQS helps keep track of which team is ready for what.\n",
      "\n",
      "To set up SQS, developers can simply create a queue, then send messages to it using APIs or messaging libraries. And here's a cool fact - did you know that Amazon itself uses SQS internally to handle millions of order requests every day? Yeah, no wonder it can scale so well!\n",
      "\n",
      "So, if you're building a scalable and reliable system that needs to handle high volumes of traffic, give SQS a try. Trust me, your app (and its users) will thank you! What do you think is the most underrated AWS service? Let me know in the comments below!\n"
     ]
    }
   ],
   "source": [
    "most_recent_idea = get_most_recent_unprocessed_idea(db)\n",
    "if most_recent_idea:\n",
    "    print(most_recent_idea.page_content) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01cf8737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/en/ljspeech/glow-tts is already downloaded.\n",
      " > vocoder_models/en/ljspeech/multiband-melgan is already downloaded.\n",
      " > Using model: glow_tts\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.1\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Vocoder Model: multiband_melgan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/Users/samihamdalla/Library/Application Support/tts/vocoder_models--en--ljspeech--multiband-melgan/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: multiband_melgan_generator\n",
      " > Discriminator Model: melgan_multiscale_discriminator\n",
      " > Text splitted to sentences.\n",
      "['Hey everyone, have you ever wondered how some of your favorite e-commerce sites can handle millions of orders in a single day without breaking a sweat?', \"Well, it's all thanks to Amazon Simple Queue Service, or SQS for short.\", 'So, what is SQS?', \"Simply put, it's a messaging service that allows different parts of an application to communicate with each other without actually being connected.\", \"Think of it like a postal system - your app sends a message to the queue, and then another part of the app can pick it up whenever it's ready.\", \"You'd use SQS when you have multiple microservices or tasks that need to be processed in a specific order, but they don't necessarily need to talk to each other directly.\", \"For example, imagine you're building an online ordering system where orders are processed by different teams - customer support, fulfillment, and shipping.\", 'Each team needs to receive the order at a different time, and SQS helps keep track of which team is ready for what.', 'To set up SQS, developers can simply create a queue, then send messages to it using APIs or messaging libraries.', \"And here's a cool fact - did you know that Amazon itself uses SQS internally to handle millions of order requests every day?\", 'Yeah, no wonder it can scale so well!', \"So, if you're building a scalable and reliable system that needs to handle high volumes of traffic, give SQS a try.\", 'Trust me, your app (and its users) will thank you!', 'What do you think is the most underrated AWS service?', 'Let me know in the comments below!']\n",
      "sɪmpli pʊt, ɪts ə mɛsɪd͡ʒɪŋ sɚvɪs ðæt əlaʊz dɪfɹənt pɑɹts əv ən æplɪkeɪʃən tə kəmjunɪkeɪt wɪθ it͡ʃ ʌðɚ wɪðaʊt ækt͡ʃəli biɪŋ kənɛktɪd.\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 4.268427610397339\n",
      " > Real-time factor: 0.039558225460003045\n"
     ]
    }
   ],
   "source": [
    "tts = TTS(model_name=\"tts_models/en/ljspeech/glow-tts\", progress_bar=False, gpu=False)\n",
    "\n",
    "# Generate audio\n",
    "tts.tts_to_file(\n",
    "    text=most_recent_idea.page_content,\n",
    "    file_path=\"output_raw.wav\"\n",
    ")\n",
    "\n",
    "# Speed up to 1.5x\n",
    "y, sr = librosa.load(\"output_raw.wav\", sr=None)\n",
    "y_fast = librosa.effects.time_stretch(y, rate=1.5)\n",
    "sf.write(\"output.wav\", y_fast, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd164ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'subtitles_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msubtitles_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_subtitles\n\u001b[32m      3\u001b[39m generate_subtitles(\n\u001b[32m      4\u001b[39m     input_text=\u001b[33m\"\u001b[39m\u001b[33mYour full script here...\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     output_file_path=\u001b[33m\"\u001b[39m\u001b[33moutput.srt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     duration=\u001b[32m60\u001b[39m,  \u001b[38;5;66;03m# total video duration\u001b[39;00m\n\u001b[32m      7\u001b[39m     subtitle_length=\u001b[32m6\u001b[39m  \u001b[38;5;66;03m# seconds per line\u001b[39;00m\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'subtitles_generator'"
     ]
    }
   ],
   "source": [
    "import stable_whisper\n",
    "\n",
    "def generate_srt_with_stable_whisper(audio_path=\"output.wav\", model_size=\"tiny\"):\n",
    "    model = stable_whisper.load_model(model_size)  # Options: tiny, base, small, medium, large\n",
    "    result = model.transcribe(audio_path)\n",
    "\n",
    "    # Save SRT file\n",
    "    result.save_as_srt(\"output.srt\")\n",
    "    print(\"✅ Subtitles saved as output.srt\")\n",
    "\n",
    "# Run it\n",
    "generate_srt_with_stable_whisper()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ig-reel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
